{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ET5003_Etivity2_Mark Devine_19187289.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markdevine/ET5003_SEM1_2021-2/blob/main/ET5003_Etivity2_Mark_Devine_19187289.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "930vlW5BrOtq"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
        "</div> \n",
        "\n",
        "#**Artificial Intelligence - MSc**\n",
        "##ET5003 - MACHINE LEARNING APPLICATIONS \n",
        "\n",
        "###Instructor: Enrique Naredo\n",
        "###ET5003_Etivity-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXD_IwUQuBF",
        "cellView": "form"
      },
      "source": [
        "#@title Current Date\n",
        "Today = '2021-08-22' #@param {type:\"date\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDKau31OjVO"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter your details here:\n",
        "Student_ID = \"19187289\" #@param {type:\"string\"}\n",
        "Student_full_name = \"Mark Devine\" #@param {type:\"string\"}\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39xGZckTpKx",
        "cellView": "form"
      },
      "source": [
        "#@title Notebook information\n",
        "Notebook_type = 'Etivity' #@param [\"Example\", \"Lab\", \"Practice\", \"Etivity\", \"Assignment\", \"Exam\"]\n",
        "Version = 'Draft' #@param [\"Draft\", \"Final\"] {type:\"raw\"}\n",
        "Submission = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A0Z6S-r6DpA"
      },
      "source": [
        "# INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRchZtf6IV-"
      },
      "source": [
        "**Piecewise regression**, extract from [Wikipedia](https://en.wikipedia.org/wiki/Segmented_regression):\n",
        "\n",
        "Segmented regression, also known as piecewise regression or broken-stick regression, is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval. \n",
        "\n",
        "* Segmented regression analysis can also be performed on \n",
        "multivariate data by partitioning the various independent variables. \n",
        "* Segmented regression is useful when the independent variables, clustered into different groups, exhibit different relationships between the variables in these regions. \n",
        "\n",
        "* The boundaries between the segments are breakpoints.\n",
        "\n",
        "* Segmented linear regression is segmented regression whereby the relations in the intervals are obtained by linear regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aajlS0WCJ8pm"
      },
      "source": [
        "***The goal is to use advanced Machine Learning methods to predict House price.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg7VCbX77eAA"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFFLThrpwibd"
      },
      "source": [
        "# Suppressing Warnings:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1770_fNrCWn"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pymc3 as pm\n",
        "import arviz as az\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYPJU_Y6O6Dq"
      },
      "source": [
        "# to plot\n",
        "import matplotlib.colors\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# to generate classification, regression and clustering datasets\n",
        "import sklearn.datasets as dt\n",
        "\n",
        "# to create data frames\n",
        "from pandas import DataFrame\n",
        "\n",
        "# to generate data from an existing dataset\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MUJdlxSPSMM"
      },
      "source": [
        "# Define the seed so that results can be reproduced\n",
        "seed = 11\n",
        "rand_state = 11\n",
        "\n",
        "# Define the color maps for plots\n",
        "color_map = plt.cm.get_cmap('RdYlBu')\n",
        "color_map_discrete = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"cyan\",\"magenta\",\"blue\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL91ShB19RPw"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESg5DGKWJSOf"
      },
      "source": [
        "Extract from this [paper](https://ieeexplore.ieee.org/document/9300074):\n",
        "\n",
        "* House prices are a significant impression of the economy, and its value ranges are of great concerns for the clients and property dealers. \n",
        "\n",
        "* Housing price escalate every year that eventually reinforced the need of strategy or technique that could predict house prices in future. \n",
        "\n",
        "* There are certain factors that influence house prices including physical conditions, locations, number of bedrooms and others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Y2pf50FlYL"
      },
      "source": [
        "1. [Download the dataset](https://github.com/UL-ET5003/ET5003_SEM1_2021-2/tree/main/Week-3). \n",
        "\n",
        "2. Upload the dataset into your folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMkdCQEmKTof"
      },
      "source": [
        "The challenge is to predict the final price of each house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQD4ZEdZWSub"
      },
      "source": [
        "### Loading the house price dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvN_DanxWkrF",
        "outputId": "f36f3685-8b39-4b95-8029-9c3284217ed6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lIL_xf5WrCZ",
        "outputId": "0f7cf50f-4526-413c-c9f6-3c849d807ed5"
      },
      "source": [
        "# Path, copy the path from your Drive\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Data/house/'\n",
        "\n",
        "# training dataset: \n",
        "filename1 = 'house_train.csv'\n",
        "train_data = path+filename1\n",
        "# test dataset: \n",
        "filename2 = 'house_test.csv'\n",
        "test_data = path+filename2\n",
        "# cost dataset: \n",
        "filename3 = 'true_price.csv'\n",
        "cost_data = path+filename3\n",
        "\n",
        "\n",
        "# MNIST Data\n",
        "# train_data = path + 'mnist_train.csv'\n",
        "# test_data = path + 'mnist_test.csv'\n",
        "\n",
        "# train data\n",
        "df_train = pd.read_csv(train_data)\n",
        "df_test = pd.read_csv(test_data)\n",
        "df_cost = pd.read_csv(cost_data)\n",
        "print(df_train.head)\n",
        "print(df_test.head)\n",
        "print(df_cost.head)\n",
        "\n",
        "# test data\n",
        "# df_test = pd.read_csv(test_data)\n",
        "# X_test_original = df_test.drop(\"label\",axis=1).values\n",
        "# y_test = df_test.label.values\n",
        "# print(X_test_original.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of          ad_id         area  ...   property_type  surface\n",
            "0       996887  Portmarnock  ...             NaN      NaN\n",
            "1       999327        Lucan  ...             NaN      NaN\n",
            "2       999559  Rathfarnham  ...             NaN      NaN\n",
            "3      9102986   Balbriggan  ...             NaN      NaN\n",
            "4      9106028      Foxrock  ...             NaN      NaN\n",
            "...        ...          ...  ...             ...      ...\n",
            "2977  12428232  Ballsbridge  ...       apartment     56.0\n",
            "2978  12428240       Rialto  ...        terraced    101.0\n",
            "2979  12428247   Smithfield  ...       apartment     55.6\n",
            "2980  12428254      Foxrock  ...  end-of-terrace     97.0\n",
            "2981  12428358     Terenure  ...   semi-detached    129.3\n",
            "\n",
            "[2982 rows x 17 columns]>\n",
            "<bound method NDFrame.head of         ad_id        area  bathrooms  ...  property_category   property_type surface\n",
            "0    12373510    Skerries        2.0  ...               sale        bungalow   142.0\n",
            "1    12422623       Lucan        2.0  ...               sale        terraced   114.0\n",
            "2    12377408      Swords        3.0  ...               sale   semi-detached   172.0\n",
            "3    12420093       Lucan        4.0  ...               sale   semi-detached   132.4\n",
            "4    12417338  Clondalkin        1.0  ...               sale   semi-detached    88.0\n",
            "..        ...         ...        ...  ...                ...             ...     ...\n",
            "495  12369815    Ringsend        1.0  ...               sale       apartment    65.0\n",
            "496  12416011  Cabinteely        3.0  ...               sale        detached   191.3\n",
            "497  12232222      Artane        1.0  ...               sale        detached   105.0\n",
            "498  11905630    Clontarf        2.0  ...               sale  end-of-terrace   130.0\n",
            "499  12394865  Drumcondra        2.0  ...               sale       apartment    71.0\n",
            "\n",
            "[500 rows x 16 columns]>\n",
            "<bound method NDFrame.head of            Id  Expected\n",
            "0    12373510  875000.0\n",
            "1    12422623  355000.0\n",
            "2    12377408  440000.0\n",
            "3    12420093  425000.0\n",
            "4    12417338  265000.0\n",
            "..        ...       ...\n",
            "495  12369815  345000.0\n",
            "496  12416011  775000.0\n",
            "497  12232222  360000.0\n",
            "498  11905630  925000.0\n",
            "499  12394865  325000.0\n",
            "\n",
            "[500 rows x 2 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PMoPLlUJ1Ly"
      },
      "source": [
        "## Training & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loLTHklwKGnV"
      },
      "source": [
        "# split data into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# training: 70% (0.7), test: 30% (0.3) \n",
        "# you could try any other combination \n",
        "# but consider 50% of training as the low boundary\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztBkSZluye87"
      },
      "source": [
        "### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rosmH4665uJ"
      },
      "source": [
        "# training dataset: \n",
        "training_file = syntPath+filename1\n",
        "# test dataset: \n",
        "testing_file = syntPath+filename2\n",
        "# cost dataset: \n",
        "cost_file = syntPath+filename3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XUFUPABMHfF"
      },
      "source": [
        "# show first data frame rows \n",
        "dftrain.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rq_p-D4yLBe"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dftrain.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqg9_uxFyZli"
      },
      "source": [
        "### Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw2_yypxMfsi"
      },
      "source": [
        "# show first data frame rows \n",
        "dftest.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXo0x2u7T7-1"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dftest.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjMH1CSEUA1A"
      },
      "source": [
        "### Expected Cost dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p63sCZeUNx3"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "dfcost.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJFJQxAS9HZK"
      },
      "source": [
        "# PIECEWISE REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ_1QsLToIDi"
      },
      "source": [
        "## Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv5j1KzzMUnm"
      },
      "source": [
        "# select some features columns just for the baseline model\n",
        "# assume not all of the features are informative or useful\n",
        "# in this exercise you could try all of them if possible\n",
        "\n",
        "featrain = ['feature_1','feature_2','feature_3','cost']\n",
        "# dropna: remove missing values\n",
        "df_subset_train = dftrain[featrain].dropna(axis=0)\n",
        "\n",
        "featest = ['feature_1','feature_2','feature_3']\n",
        "df_subset_test  =  dftest[featest].dropna(axis=0)\n",
        "\n",
        "# cost\n",
        "df_cost = df_cost[df_cost.index.isin(df_subset_test.index)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZK2kfygoIDi"
      },
      "source": [
        "# model\n",
        "with pm.Model() as model:\n",
        "    #prior over the parameters of linear regression\n",
        "    alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "    #we have one beta for each column of Xn\n",
        "    beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn_train.shape[1])\n",
        "    #prior over the variance of the noise\n",
        "    sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "    #linear regression model in matrix form\n",
        "    mu = alpha + pm.math.dot(beta, Xn_train.T)\n",
        "    #likelihood, be sure that observed is a 1d vector\n",
        "    like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn_train[:,0])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIskuS3ToIDk"
      },
      "source": [
        "# prediction\n",
        "ll=np.mean(posterior['alpha']) + np.dot(np.mean(posterior['beta'],axis=0), Xn_test.T)\n",
        "y_pred_BLR = np.exp(yscaler.inverse_transform(ll.reshape(-1,1)))[:,0]\n",
        "print(\"MAE = \",(np.mean(abs(y_pred_BLR - y_test))))\n",
        "print(\"MAPE = \",(np.mean(abs(y_pred_BLR - y_test) / y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_jBBKvtoIDk"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYFvbgYDaEOS"
      },
      "source": [
        "### Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iphQ53UE0iVw"
      },
      "source": [
        "# training gaussian mixture model \n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "gmm = GaussianMixture(n_components=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h51OhBV5Z4tY"
      },
      "source": [
        "### Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNvx_KxrLt90"
      },
      "source": [
        "# train clusters\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wTT4220zFNx"
      },
      "source": [
        "# test clusters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXF25ZDYoIDl"
      },
      "source": [
        "## Piecewise Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1e-4ruvaJci"
      },
      "source": [
        "# model_0\n",
        "with pm.Model() as model_0:\n",
        "  # prior over the parameters of linear regression\n",
        "  alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "  # we have a beta for each column of Xn0\n",
        "  beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn0.shape[1])\n",
        "  # prior over the variance of the noise\n",
        "  sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "  # linear regression relationship\n",
        "  #linear regression model in matrix form\n",
        "  mu = alpha + pm.math.dot(beta, Xn0.T)\n",
        "  # likelihood, be sure that observed is a 1d vector\n",
        "  like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn0[:,0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHBgUe1pcZQQ"
      },
      "source": [
        "##Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSEdYAUoIDn"
      },
      "source": [
        "### Only Cluster 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgMUwBO7oIDq"
      },
      "source": [
        "## Overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMY9rDvVoIDq"
      },
      "source": [
        "## Test set performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGmB9BNkoIDr"
      },
      "source": [
        "### PPC on the Test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0GYCpwEM09T"
      },
      "source": [
        "# SUMMARY"
      ]
    }
  ]
}